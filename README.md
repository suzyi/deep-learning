# deep-learning
## Recommendation
### deep learning courses
+ [EPFL course](https://documents.epfl.ch/users/f/fl/fleuret/www/dlc/#information). This is a deep learning course provided by senior researcher FRANÇOIS FLEURET [(His homepage)](https://www.idiap.ch/~fleuret/), who is now an adjunct faculty in the School of Engineering of the École Polytechnique Fédérale de Lausanne.

#### scholars studying the theory of deep learning
+ [Shiyu Liang](https://www.shiyu-liang.com/), university of Illinois at Urbana-Champaign. Selected publications: [Why Deep Neural Network For Function Approximation? - ICLR 2017](https://arxiv.org/abs/1610.04161)
+ [Raman Arora](http://www.cs.jhu.edu/~raman/Home.html), assistant prof in John Hopkin univ. Selected papers: [Understanding deep neural networks with rectified linear units - ICLR 2018](https://arxiv.org/abs/1611.01491).
+ [Ruoyu Sun](https://sites.google.com/site/ruoyusun88/home), assistant professor in UIUC, was a postdoctoral scholar with Prof. Yinyu Ye.
+ [Yuandong Tian](http://www.yuandong-tian.com/), a Facebook AI researcher, got his phd from CMU. There're many practical interesting applications (including "A Reimplementation of AlphaGoZero", "") shown in his personal home page. Selected papers for theoretical understanding of neural networks includes [Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima - ICML 2018](https://arxiv.org/abs/1712.00779) and [An Analytical Formula of Population Gradient for two-layered ReLU network and its Applications in Convergence and Critical Point Analysis](https://arxiv.org/abs/1703.00560), though I haven't read these two papers yet.
+ [Tenyu Ma](https://ai.stanford.edu/~tengyuma/) Graduated from Tsinghua (got his bachelor's degree at Andrew Chi-Chih Yao's CS pilot class) and Princeton (got his doctor's degree), now works in Stanford as a assitant professor.
+ [Thiago Serra](https://thiagoserra.com/) got phd from CMU. His research interests are deep learning (with [ICML-2018](https://arxiv.org/abs/1711.02114) paper focusing on mixed integer programing that applied in Relu DNN got accepted), optimization and etc. 
#### depth-width tradeoff
+ Ronen Eldan and Ohad Shamir. The Power of Depth for Feedforward Neural Networks
+ [Raman Arora](http://www.cs.jhu.edu/~raman/Home.html), Johns Hopkins University. Selected publications: [Understanding Deep Neural Networks with Rectified Linear Units - ICLR 2018](https://arxiv.org/pdf/1611.01491.pdf)
#### optimization
## model
### Boltzmann machines
### GAN
### Adversirial neural networks
## Methodology
### deep learning
### transferring learning
### reinforcement learning
